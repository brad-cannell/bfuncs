---
title: "R Notebook"
date: "Created: 201X-XX-XX <br> Updated: `r Sys.Date()`"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(comment = NA)
Sys.setenv(TZ = "US/Central")
```

```{r load_packages, message=FALSE}
# Load packages
library(tidyverse)
library(bfuncs)
```

```{r}
data(mtcars)
```

```{r}
df <- mtcars %>% 
  group_by(am, vs) %>% 
  freq_table()

df
```

# Calculate Pearson's Chi-square

Pearson's chi-square is given by:

$$\chi^2=\sum \frac{(observed_{ij} - expected_{ij})^2}{expected_{ij}}$$

where,

$$expected_{ij} = \frac{row \ total * column \ total}{total}$$

```{r}
row_var <- df %>% select(1) %>% names() %>% rlang::sym()
col_var <- df %>% select(2) %>% names() %>% rlang::sym()
```

```{r}
df2 <- df %>% 
  group_by(!!col_var) %>% 
  mutate(n_col = sum(n)) %>%  # Find marginal totals for "columns"
  ungroup() %>% 
  mutate(
    expected_n = (n_row * n_col) / n_total,
    chi2_contrib = (n - expected_n)**2 / expected_n,
    chi2_pearson = sum(chi2_contrib),
    r = unique(!!row_var) %>% length(),
    c = unique(!!col_var) %>% length(),
    df = (r -1) * (c - 1),
    p_pearson = pchisq(chi2_pearson, df, lower.tail = FALSE)
  )

class(df2) <- c("freq_table_two_way", class(df2))

df2
```

There is one problem with the chi-square test, which is that the sampling distribution of the test statistic has an approximate chi-square distribution. The larger the sample is, the better this approximation becomes, and in large samples the approximation is good enough to not worry about the fact that it is an approximation. However, in small samples the approximation is not good enough, making significance tests of the chi-square distribution inaccurate.

Field, Andy; Miles, Jeremy; Field, Zoe. Discovering Statistics Using R (p. 816). SAGE Publications. Kindle Edition. 

# Fisher's exact test

http://quantpsy.org/fisher/fisher.htm

The exact probability of the chi-square statistic is given by:

$$\chi^2 = \frac{(a+b)! + (c+d)! + (a+c)! +(b+d)!}{a! + b! + c! + d!}$$

```{r}
numerator <- factorial((12 + 7)) * factorial((6 + 7)) * factorial((12 + 6)) * factorial((7 + 7))
denominator <- factorial(12) * factorial(7) * factorial(6) * factorial(7) * factorial(32)
fisher = numerator / denominator
```

```{r}
ft <- stats::fisher.test(mtcars$am, mtcars$vs)
ft$p.value
```

```{r}
x <- unlist(df2[, 3])
mx <- matrix(x, nrow = 2, byrow = TRUE)
fisher.test(mx)
```


Maybe I should just calculate other p-values outside of dplyr, then put add them back inot the tables.



How do you calculate all other cases as or more extreme?

```{r}
df3 <- df2 %>% 
  mutate(
    row_margins = unique(n_row) %>% list(),
    col_margins = unique(n_col) %>% list(),
    row_factorial = row_margins %>% unlist %>% unique %>% factorial() %>% list(),
    col_factorial = col_margins %>% unlist %>% unique %>% factorial() %>% list(),
    numerator = c(unique(unlist(row_factorial)), unique(unlist(col_factorial))) %>% sum
    
  ) 

View(df3)
```


```{r}
# Test against gmodels
gmodels::CrossTable(mtcars$am, mtcars$vs, expected = TRUE, fisher = TRUE)
```

Test against SAS too
